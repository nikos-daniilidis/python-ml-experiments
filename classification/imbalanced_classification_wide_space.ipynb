{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import log_loss, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_class_limits(df, x1_col, x2_col, target_column, extend_factor = 1.5):\n",
    "    \"\"\"\n",
    "    Find the limits of the positive class, extended by a factor\n",
    "    \n",
    "    df: data frame holding the data\n",
    "    x1_col, x2_col: the columns holding the input features \n",
    "    target_column: the column holding the target variable\n",
    "    extend_factor: factor by which to extend the limits\n",
    "    \n",
    "    return: x1_min, x1_max, x2_min, x2_max\n",
    "    \"\"\"\n",
    "    x_matr = df[df[target_column] == 1][[x1_col, x2_col]].as_matrix()\n",
    "    x1_min, x1_max = np.min(x_matr[:,0]),  np.max(x_matr[:,0])\n",
    "    x2_min, x2_max =  np.min(x_matr[:,1]),  np.max(x_matr[:,1])\n",
    "    mid1, ext1 = (x1_min + x1_max) / 2., (-x1_min + x1_max) / 2.\n",
    "    mid2, ext2 = (x2_min + x2_max) / 2., (-x2_min + x2_max) / 2.\n",
    "    return mid1 - extend_factor * ext1, mid1 + extend_factor * ext1,  mid2 - extend_factor * ext2, mid2 + extend_factor * ext2,\n",
    "\n",
    "\n",
    "def create_grid(x1_min, x1_max, x2_min, x2_max, num_points=101):\n",
    "    \"\"\"\n",
    "    Create a grid with num_points points in each dimension. \n",
    "    \n",
    "    x1_min, x1_max, x2_min, x2_max: float, the grid limits\n",
    "    num_points: int\n",
    "    \"\"\"\n",
    "    dx1 = (x1_max - x1_min) / (num_points - 1)\n",
    "    dx2 = (x2_max - x2_min) / (num_points - 1)\n",
    "    xx, yy = np.meshgrid(np.arange(x1_min, x1_max, dx1),\n",
    "                         np.arange(x2_min, x2_max, dx2))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_decision_boundary(ax, clf, feat_mesh, mesh_shape, cm = plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Plot the decision boundary. For that, we will assign a color to each\n",
    "    point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    \n",
    "    ax: an axis object\n",
    "    clf: trained classifier object\n",
    "    feat_mesh: numpy array, each column has the values of input features on a flattened mesh\n",
    "    cm: colormap to use in the plot\n",
    "    \"\"\"\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(feat_mesh)\n",
    "    else:\n",
    "        Z = clf.predict_proba(feat_mesh)[:, 1]\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    xx, yy = feat_mesh[:, 0].reshape(mesh_shape), feat_mesh[:, 1].reshape(mesh_shape)\n",
    "    Z = Z.reshape(mesh_shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "    return ax\n",
    "\n",
    "    \n",
    "def plot_points(ax, X, y, cm_bright = ListedColormap(['#FF0000', '#0000FF']), alpha=0.3):\n",
    "    \"\"\"\n",
    "    Plot the training and test points.\n",
    "    \"\"\"\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright, alpha=alpha)\n",
    "    # testing points\n",
    "    #ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "    #           alpha=0.6)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def form_figure(ax, xx, yy, name, score):\n",
    "    \"\"\"\n",
    "    Create a generic figure template.\n",
    "    \"\"\"\n",
    "    ##ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(name)\n",
    "    ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "            size=15, horizontalalignment='right')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def balance_data(df, target_column, balabce_ratio = 1.):\n",
    "    \"\"\"\n",
    "    Pick a random sample from a data frame, such that all examples \n",
    "    of the minority class are kept, and the ratio between classes is \n",
    "    balance_ratio.\n",
    "    \n",
    "    df: pandas DataFrame\n",
    "    target_column: the label of the target column\n",
    "    balance_ratio: the balance of the two classes in the resulting data frame\n",
    "    \"\"\"\n",
    "    class_fraction = df[target_column].mean()\n",
    "    df_r = df.copy()\n",
    "    df_r['random'] = np.random.uniform(low=0., high=1., size=df.shape[0])\n",
    "    return df_r[((df_r['random'] <= class_fraction) & (df_r[target_column] == 0)) | (df_r[target_column] == 1)]\n",
    "\n",
    "\n",
    "def assign_class_quadr(x1, x2, n1, n2, alpha):\n",
    "    \"\"\"\n",
    "    Generate the class labels for the data, according to a quadratic boundary. \n",
    "    Positive class is x2 >= alpha * x1^2\n",
    "    \n",
    "    x1, x2: numpy array\n",
    "    n1, n2: numpy arrays with noise in each coordinate (generates a random shift for each point's class)\n",
    "    alpha: float, the coefficient for the quadratic function\n",
    "    \"\"\"\n",
    "    return np.greater_equal(x2+n2, alpha * np.power(x1+n1, 2)).astype('float')\n",
    "\n",
    "\n",
    "def assign_class_lin(x1, x2, n1, n2, kappa):\n",
    "    \"\"\"\n",
    "    Generate the class labels for the data, according to a linear boundary. \n",
    "    Positive class is x1 + x2 <= kappa\n",
    "    \n",
    "    x1, x2: numpy arrays with coordinates\n",
    "    n1, n2: numpy arrays with noise in each coordinate (generates a random shift for each point's class)\n",
    "    kappa: float, the intercept of the boundary with the axes\n",
    "    \"\"\"\n",
    "    return np.less_equal(x1 + n1 + x2 + n2, kappa).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The rule for class I is: \n",
    "\n",
    "$$C_{I} = \\left\\{ (x_1,x_2):\\, x_2 \\geq \\alpha \\ x_1^2 \\right\\}$$\n",
    "\n",
    "Then, for data bounded in the area $|x_1|, |x_2| \\leq 1$, the area occupied by class I is:\n",
    "\n",
    "$$2\\,\\int_{0}^{1}\\sqrt{y/\\alpha}\\,dy = \\frac{4}{3\\sqrt{\\alpha}}$$\n",
    "\n",
    "and the relative fraction of class I is $$1/(6\\,w\\,\\sqrt{\\alpha})$$\n",
    "\n",
    "where $$2\\,w$$ is the area of train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Generate data and assign classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alph = 1.\n",
    "ns  = 0.01\n",
    "w = 0.2\n",
    "X1 = np.random.uniform(low=-1., high=1., size=10000)\n",
    "X2 = np.random.uniform(low=-w, high=w, size=10000)\n",
    "n1 = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "n2 = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "Y = np.transpose(assign_class_quadr(X1, X2, n1, n2, alph))\n",
    "\n",
    "X = np.vstack((X1, X2, np.power(X1, 2), np.power(X2, 2))).T\n",
    "\n",
    "df = pd.DataFrame(data=np.vstack((X.T, Y)).T, columns=['X1', 'X2', 'X1sq', 'X2sq', 'Y'])\n",
    "df_b = balance_data(df, target_column='Y', balabce_ratio=1.)\n",
    "X_b = df_b[['X1', 'X2', 'X1sq', 'X2sq']].as_matrix()\n",
    "Y_b = np.ravel(df_b[['Y']].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=30, class_weight='auto', cv=6, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='ovr', n_jobs=3, penalty='l2', refit=True,\n",
       "           scoring=None, solver='lbfgs', tol=1e-06, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(Cs=30, class_weight='auto', cv=6, dual=False,\n",
    "                           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
    "                           multi_class='ovr', n_jobs=3, penalty='l2', refit=True,\n",
    "                           scoring=None, solver='lbfgs', tol=1e-06, verbose=0)\n",
    "\n",
    "clf_b = LogisticRegressionCV(Cs=30, class_weight='auto', cv=6, dual=False, \n",
    "                             fit_intercept=True, intercept_scaling=1.0, max_iter=1000, \n",
    "                             multi_class='ovr', n_jobs=3, penalty='l2', refit=True, \n",
    "                             scoring=None, solver='lbfgs', tol=1e-06, verbose=0)\n",
    "\n",
    "clf.fit(X, Y)\n",
    "clf_b.fit(X_b, Y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of class 1: 0.833\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "X1t = np.random.uniform(low=-1., high=1., size=10000)\n",
    "X2t = np.random.uniform(low=-w, high=w, size=10000)\n",
    "n1t = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "n2t = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "\n",
    "Yt = np.transpose(assign_class_quadr(X1t, X2t, n1t, n2t, alph))\n",
    "\n",
    "Xt = np.vstack((X1t, X2t, np.power(X1, 2), np.power(X2, 2))).T\n",
    "\n",
    "dft = pd.DataFrame(data=np.vstack((Xt.T, Yt)).T, columns=['X1', 'X2', 'X1sq', 'X2sq', 'Y'])\n",
    "dft_b = balance_data(dft, target_column='Y', balabce_ratio=1.)\n",
    "X_b = dft_b[['X1', 'X2', 'X1sq', 'X2sq']].as_matrix()\n",
    "Y_b = np.ravel(dft_b[['Y']].as_matrix())\n",
    "print \"Fraction of class 1: %4.3f\" % (1/(6. * w * np.sqrt(alph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on balanced data: 0.792\n",
      "Score on unbalanced data: 0.786\n",
      "Log loss on balanced data: 4.083\n",
      "Log loss on unbalanced data: 2.961\n",
      "ROC-AUC on balanced data: 0.628\n",
      "ROC-AUC on unbalanced data: 0.625\n"
     ]
    }
   ],
   "source": [
    "print \"Score on balanced data: %4.3f\" %clf.score(Xt, Yt)\n",
    "print \"Score on unbalanced data: %4.3f\" %clf_b.score(Xt, Yt)\n",
    "\n",
    "y_pred = clf.predict_proba(Xt)\n",
    "yb_pred = clf_b.predict_proba(Xt)\n",
    "print \"Log loss on balanced data: %4.3f\" %log_loss(Yt, y_pred)\n",
    "print \"Log loss on unbalanced data: %4.3f\" %log_loss(Yt, yb_pred)\n",
    "\n",
    "print \"ROC-AUC on balanced data: %4.3f\" % roc_auc_score(Yt, y_pred[:,1])\n",
    "print \"ROC-AUC on unbalanced data: %4.3f\" % roc_auc_score(Yt, yb_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_min, x1_max, x2_min, x2_max = get_class_limits(df, 'X1', 'X2', 'Y', extend_factor = 1.5)\n",
    "x1b_min, x1b_max, x2b_min, x2b_max = get_class_limits(df_b, 'X1', 'X2', 'Y', extend_factor = 1.5)\n",
    "\n",
    "xx, yy =  create_grid(x1_min, x1_max, x2_min, x2_max, num_points=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1 = form_figure(ax1, xx, yy, name='Unbalanced data set', score=clf.score(Xt, Yt))\n",
    "ax1 = plot_decision_boundary(ax1, clf, \n",
    "                             np.c_[xx.ravel(), \n",
    "                                   yy.ravel(), \n",
    "                                   np.power(xx, 2).ravel(), \n",
    "                                   np.power(yy, 2).ravel()],\n",
    "                             xx.shape, cm=plt.cm.RdBu)\n",
    "ax1 = plot_points(ax1, Xt, Yt)\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2 = form_figure(ax2, xx, yy, name='Balanced data set', score=clf_b.score(Xt, Yt))\n",
    "ax2 = plot_decision_boundary(ax2, clf_b, \n",
    "                             np.c_[xx.ravel(), \n",
    "                                   yy.ravel(), \n",
    "                                   np.power(xx, 2).ravel(), \n",
    "                                   np.power(yy, 2).ravel()],\n",
    "                             yy.shape, cm=plt.cm.RdBu)\n",
    "ax2 = plot_points(ax2, X_b, Y_b)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thrs = roc_curve(Yt, y_pred[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, thrs = roc_curve(Yt, yb_pred[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic boundary, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alph = 1\n",
    "#I = np.ones(50000)\n",
    "X1 = np.random.uniform(low=-1., high=1., size=10000)\n",
    "X2 = np.random.uniform(low=-w, high=w, size=10000)\n",
    "n1 = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "n2 = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "\n",
    "Y = np.transpose(assign_class_quadr(X1, X2, n1, n2, alph))\n",
    "\n",
    "## I now X1^2 wil be important, add it as a feature\n",
    "X = np.vstack((X1, X2)).T\n",
    "\n",
    "df = pd.DataFrame(data=np.vstack((X.T, Y)).T, columns=['X1', 'X2', 'Y'])\n",
    "df_b = balance_data(df, target_column='Y', balabce_ratio=1.)\n",
    "X_b = df_b[['X1', 'X2']].as_matrix()\n",
    "Y_b = np.ravel(df_b[['Y']].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='auto', coef0=0.0, degree=3,\n",
       "  gamma=0.0, kernel='rbf', max_iter=-1, probability=True,\n",
       "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(class_weight='auto', kernel='rbf', probability=True)\n",
    "clf_b = svm.SVC(class_weight='auto', kernel='rbf', probability=True)\n",
    "\n",
    "clf.fit(X, Y)\n",
    "clf_b.fit(X_b, Y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of class 1: 0.146\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "X1t = np.random.uniform(low=-1., high=1., size=10000)\n",
    "X2t = np.random.uniform(low=-w, high=w, size=10000)\n",
    "n1t = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "n2t = np.random.normal(loc=0.0, scale=ns, size=10000)\n",
    "\n",
    "Yt = np.transpose(assign_class_quadr(X1t, X2t, n1t, n2t, alph))\n",
    "\n",
    "Xt = np.vstack((X1t, X2t)).T\n",
    "\n",
    "dft = pd.DataFrame(data=np.vstack((Xt.T, Yt)).T, columns=['X1', 'X2', 'Y'])\n",
    "dft_b = balance_data(dft, target_column='Y', balabce_ratio=1.)\n",
    "X_b = dft_b[['X1', 'X2']].as_matrix()\n",
    "Y_b = np.ravel(dft_b[['Y']].as_matrix())\n",
    "print \"Fraction of class 1: %4.3f\" % Yt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on balanced data: 0.939\n",
      "Score on unbalanced data: 0.932\n",
      "Log loss on balanced data: 0.025\n",
      "Log loss on unbalanced data: 0.046\n",
      "ROC-AUC on balanced data: 0.999\n",
      "ROC-AUC on unbalanced data: 0.999\n"
     ]
    }
   ],
   "source": [
    "print \"Score on balanced data: %4.3f\" %clf.score(Xt, Yt)\n",
    "print \"Score on unbalanced data: %4.3f\" %clf_b.score(Xt, Yt)\n",
    "\n",
    "y_pred = clf.predict_proba(Xt)\n",
    "yb_pred = clf_b.predict_proba(Xt)\n",
    "print \"Log loss on balanced data: %4.3f\" %log_loss(Yt, y_pred)\n",
    "print \"Log loss on unbalanced data: %4.3f\" %log_loss(Yt, yb_pred)\n",
    "\n",
    "print \"ROC-AUC on balanced data: %4.3f\" % roc_auc_score(Yt, y_pred[:,1])\n",
    "print \"ROC-AUC on unbalanced data: %4.3f\" % roc_auc_score(Yt, yb_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_min, x1_max, x2_min, x2_max = get_class_limits(df, 'X1', 'X2', 'Y', extend_factor = 1.5)\n",
    "x1b_min, x1b_max, x2b_min, x2b_max = get_class_limits(df_b, 'X1', 'X2', 'Y', extend_factor = 1.5)\n",
    "\n",
    "xx, yy =  create_grid(x1_min, x1_max, x2_min, x2_max, num_points=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1 = form_figure(ax1, xx, yy, name='Unbalanced data set', score=clf.score(Xt, Yt))\n",
    "ax1 = plot_decision_boundary(ax1, clf, \n",
    "                             np.c_[xx.ravel(), \n",
    "                                   yy.ravel()],\n",
    "                             xx.shape, cm=plt.cm.RdBu)\n",
    "ax1 = plot_points(ax1, Xt, Yt)\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2 = form_figure(ax2, xx, yy, name='Balanced data set', score=clf_b.score(Xt, Yt))\n",
    "ax2 = plot_decision_boundary(ax2, clf_b, \n",
    "                             np.c_[xx.ravel(), \n",
    "                                   yy.ravel()],\n",
    "                             yy.shape, cm=plt.cm.RdBu)\n",
    "ax2 = plot_points(ax2, X_b, Y_b)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thrs = roc_curve(Yt, y_pred[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, thrs = roc_curve(Yt, yb_pred[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kappa = 0.1\n",
    "# Train data\n",
    "X1 = np.random.uniform(low=0., high=1., size=50000)\n",
    "X2 = np.random.uniform(low=0., high=1., size=50000)\n",
    "Y = np.transpose(assign_class_lin(X1, X2, kappa))\n",
    "\n",
    "## I now X1^2 wil be important, add it as a feature\n",
    "X = np.vstack((X1, X2)).T\n",
    "\n",
    "df = pd.DataFrame(data=np.vstack((X.T, Y)).T, columns=['X1', 'X2', 'Y'])\n",
    "df_b = balance_data(df, target_column='Y', balabce_ratio=1.)\n",
    "X_b = df_b[['X1', 'X2']].as_matrix()\n",
    "Y_b = np.ravel(df_b[['Y']].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=200,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', refit=True,\n",
       "           scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(class_weight='auto', max_iter=200)\n",
    "clf_b = LogisticRegressionCV(class_weight=None, max_iter=200)\n",
    "\n",
    "clf.fit(X, Y)\n",
    "clf_b.fit(X_b, Y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of class 1: 0.005\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "X1t = np.random.uniform(low=0., high=1., size=50000)\n",
    "X2t = np.random.uniform(low=0., high=1., size=50000)\n",
    "Yt = np.transpose(assign_class_lin(X1t, X2t, kappa))\n",
    "\n",
    "Xt = np.vstack((X1t, X2t)).T\n",
    "\n",
    "dft = pd.DataFrame(data=np.vstack((Xt.T, Yt)).T, columns=['X1', 'X2', 'Y'])\n",
    "dft_b = balance_data(dft, target_column='Y', balabce_ratio=1.)\n",
    "X_b = dft_b[['X1', 'X2']].as_matrix()\n",
    "Y_b = np.ravel(dft_b[['Y']].as_matrix())\n",
    "print \"Fraction of class 1: %4.3f\" % Yt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on balanced data: 0.997\n",
      "Score on unbalanced data: 0.971\n",
      "Log loss on balanced data: 0.006\n",
      "Log loss on unbalanced data: 0.585\n"
     ]
    }
   ],
   "source": [
    "print \"Score on balanced data: %4.3f\" %clf.score(Xt, Yt)\n",
    "print \"Score on unbalanced data: %4.3f\" %clf_b.score(Xt, Yt)\n",
    "\n",
    "y_pred = clf.predict_proba(Xt)\n",
    "yb_pred = clf_b.predict_proba(Xt)\n",
    "print \"Log loss on balanced data: %4.3f\" %log_loss(Yt, y_pred)\n",
    "print \"Log loss on unbalanced data: %4.3f\" %log_loss(Yt, yb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_min, x1_max, x2_min, x2_max = get_class_limits(df, 'X1', 'X2', 'Y', extend_factor = 1.5)\n",
    "x1b_min, x1b_max, x2b_min, x2b_max = get_class_limits(df_b, 'X1', 'X2', 'Y', extend_factor = 1.5)\n",
    "\n",
    "xx, yy =  create_grid(x1_min, x1_max, x2_min, x2_max, num_points=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1 = form_figure(ax1, xx, yy, name='Unbalanced data set', score=clf.score(Xt, Yt))\n",
    "ax1 = plot_decision_boundary(ax1, clf, \n",
    "                             np.c_[xx.ravel(), yy.ravel()],\n",
    "                             xx.shape, cm=plt.cm.RdBu)\n",
    "ax1 = plot_points(ax1, Xt, Yt)\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2 = form_figure(ax2, xx, yy, name='Balanced data set', score=clf_b.score(Xt, Yt))\n",
    "ax2 = plot_decision_boundary(ax2, clf_b, \n",
    "                             np.c_[xx.ravel(), yy.ravel()],\n",
    "                             xx.shape, cm=plt.cm.RdBu)\n",
    "ax2 = plot_points(ax2, X_b, Y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
